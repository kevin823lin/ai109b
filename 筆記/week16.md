# 第十六周筆記

## 機器學習

機器學習理論主要是設計和分析一些讓電腦可以自動「學習」的演算法。機器學習演算法是一類從資料中自動分析獲得規律，並利用規律對未知資料進行預測的演算法。因為學習演算法中涉及了大量的統計學理論，機器學習與推斷統計學聯絡尤為密切，也被稱為統計學習理論。演算法設計方面，機器學習理論關注可以實現的，行之有效的學習演算法。很多推論問題屬於無程式可循難度，所以部分的機器學習研究是開發容易處理的近似演算法。

### 分類

機器學習可以分成下面幾種類別：

1. 監督學習從給定的訓練資料集中學習出一個函式，當新的資料到來時，可以根據這個函式預測結果。監督學習的訓練集要求是包括輸入和輸出，也可以說是特徵和目標。訓練集中的目標是由人標註的。常見的監督學習演算法包括回歸分析和統計分類。

1. 無監督學習與監督學習相比，訓練集沒有人為標註的結果。常見的無監督學習演算法有生成對抗網路（GAN）、聚類。

1. 半監督學習介於監督學習與無監督學習之間。

1. 增強學習機器為了達成目標，隨著環境的變動，而逐步調整其行為，並評估每一個行動之後所到的回饋是正向的或負向的。

### 蒙地卡羅方法

蒙地卡羅方法，是指使用亂數來解決很多計算問題的方法。是因應科學技術的發展和電腦的發明，而提出的一種以機率統計理論為指導的數值計算方法。

* 蒙地卡羅方法可以粗略地分成兩類：

    1. 所求解的問題本身具有內在的隨機性，藉助電腦的運算能力可以直接類比這種隨機的過程。

    1. 所求解問題可以轉化為某種隨機分布的特徵數，比如隨機事件出現的機率，或者隨機變數的期望值。通過隨機抽樣的方法，以隨機事件出現的頻率估計其機率，或者以抽樣的數字特徵估算隨機變數的數字特徵，並將其作為問題的解。

* 在解決實際問題的時候應用蒙地卡羅方法主要有兩部分工作：

    1. 用蒙地卡羅方法類比某一過程時，需要產生各種機率分布的隨機變數。
    2. 用統計方法把模型的數字特徵估計出來，從而得到實際問題的數值解。

#### 下圖使用蒙地卡羅方法估算 π 值。放置 30000 個隨機點後，π 的估算值與真實值相差 0.07%

![蒙地卡羅方法](https://upload.wikimedia.org/wikipedia/commons/8/84/Pi_30K.gif)

### 馬可夫鏈

馬可夫鏈為狀態空間中經過從一個狀態到另一個狀態的轉換的隨機過程。該過程要求具備「無記憶」的性質：下一狀態的機率分布只能由當前狀態決定，在時間序列中它前面的事件均與之無關。

在馬可夫鏈的每一步，系統根據機率分布，可以從一個狀態變到另一個狀態，也可以保持當前狀態。狀態的改變叫做轉移，與不同的狀態改變相關的機率叫做轉移機率。隨機漫步就是馬可夫鏈的例子。隨機漫步中每一步的狀態是在圖形中的點，每一步可以移動到任何一個相鄰的點，在這裡移動到每一個點的機率都是相同的（無論之前漫步路徑是如何的）。

* 討論不是互相獨立的一些事件。

* 下一狀態的機率分布只能由當前狀態決定，在時間序列中它前面的事件均與之無關。

* 種具有狀態的隨機過程

* ex: 轉移矩陣的應用問題

#### 下圖為一個具有兩個轉換狀態的馬可夫鏈

![馬可夫鏈](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Markovkate_01.svg/330px-Markovkate_01.svg.png)

### 吉布斯採樣

吉布斯採樣是統計學中用於馬爾科夫蒙特卡洛的一種算法，用於在難以直接採樣時從某一多變量概率分布中近似抽取樣本序列。該序列可用於近似聯合分布、部分變量的邊緣分布或計算積分。某些變量可能為已知變量，故對這些變量並不需要採樣。

### 隱藏式馬可夫模型

隱藏式馬可夫模型用來描述一個含有隱含未知參數的馬可夫過程。其難點是從可觀察的參數中確定該過程的隱含參數。然後利用這些參數來作進一步的分析，例如圖型識別。

在正常的馬可夫模型中，狀態對於觀察者來說是直接可見的。這樣狀態的轉換機率便是全部的參數。而在隱藏式馬可夫模型中，狀態並不是直接可見的，但受狀態影響的某些變數則是可見的。每一個狀態在可能輸出的符號上都有一機率分布。因此輸出符號的序列能夠透露出狀態序列的一些資訊。

#### 下圖為一個隱藏式馬可夫模型狀態變遷圖

![隱藏式馬可夫模型](https://upload.wikimedia.org/wikipedia/commons/d/d5/Hmm.png)

x — 隱含狀態

y — 可觀察的輸出

a — 轉換機率

b — 輸出機率

### 維特比演算法

維特比演算法是一種動態規劃演算法。它用於尋找最有可能產生觀測事件序列的維特比路徑 —— 隱含狀態序列，特別是在馬可夫資訊源上下文和隱藏式馬可夫模型中。

#### 下圖為一個維特比演算法的例子

![維特比演算法](https://upload.wikimedia.org/wikipedia/commons/0/0c/An_example_of_HMM.png)

想像一個鄉村診所。村民有著非常理想化的特性，要麼健康要麼發燒。他們只有問診所的醫生的才能知道是否發燒。 聰明的醫生通過詢問病人的感覺診斷他們是否發燒。村民只回答他們感覺正常、頭暈或冷。

假設一個病人每天來到診所並告訴醫生他的感覺。醫生相信病人的健康狀況如同一個離散馬可夫鏈。病人的狀態有兩種「健康」和「發燒」，但醫生不能直接觀察到，這意味著狀態對他是「隱含」的。每天病人會告訴醫生自己有以下幾種由他的健康狀態決定的感覺的一種：正常、冷或頭暈。這些是觀察結果。 整個系統為一個隱藏式馬可夫模型(HMM)。

### EM演算法

EM演算法在統計中被用於尋找，依賴於不可觀察的隱性變量的概率模型中，參數的最大似然估計。

#### 實作

* 執行 `em.py`

    ```text
    PS D:\檔案\課程\1092\人工智慧\ai\06-learn\05-em> python .\em.py
    pA=[0.6, 0.4] pB=[0.5, 0.5] delta=9.9999
    pA=[0.71301224 0.28698776] pB=[0.58133931 0.41866069] delta=0.11301223540051619 
    pA=[0.74529204 0.25470796] pB=[0.56925575 0.43074425] delta=0.0322798006814784  
    pA=[0.76809883 0.23190117] pB=[0.54953591 0.45046409] delta=0.022806798285326613
    pA=[0.78316458 0.21683542] pB=[0.53461745 0.46538255] delta=0.015065749932652417
    pA=[0.79105525 0.20894475] pB=[0.52628117 0.47371883] delta=0.008336287117588381
    pA=[0.79453254 0.20546746] pB=[0.52239044 0.47760956] delta=0.003890729512057156
    pA=[0.79592867 0.20407133] pB=[0.52072988 0.47927012] delta=0.001660559431849007
    ```

### K-近鄰演算法（最近鄰居法）

K-近鄰演算法是一種用於分類和迴歸的無母數統計方法。

在下列兩種情況下，輸入包含特徵空間（Feature Space）中的k個最接近的訓練樣本。

1. 在k-NN分類中，輸出是一個分類族群。一個物件的分類是由其鄰居的「多數表決」確定的，k個最近鄰居（k為正整數，通常較小）中最常見的分類決定了賦予該物件的類別。若k = 1，則該物件的類別直接由最近的一個節點賦予。
2. 在k-NN迴歸中，輸出是該物件的屬性值。該值是其k個最近鄰居的值的平均值。

### 決策樹

決策論中，決策樹由一個決策圖和可能的結果（包括資源成本和風險）組成， 用來創建到達目標的規劃。

機器學習中，決策樹是一個預測模型；他代表的是對象屬性與對象值之間的一種映射關係。樹中每個節點表示某個對象，而每個分叉路徑則代表某個可能的屬性值，而每個葉節點則對應從根節點到該葉節點所經歷的路徑所表示的對象的值。決策樹僅有單一輸出，若欲有複數輸出，可以建立獨立的決策樹以處理不同輸出。 數據挖掘中決策樹是一種經常要用到的技術，可以用於分析數據，同樣也可以用來作預測。

從數據產生決策樹的機器學習技術叫做決策樹學習,通俗說就是決策樹。

一個決策樹包含三種類型的節點：

1. 決策節點：通常用矩形框來表示

1. 機會節點：通常用圓圈來表示

1. 終結點：通常用三角形來表示

![決策樹](https://upload.wikimedia.org/wikipedia/commons/a/ad/Decision-Tree-Elements.png)

## 參考資料

* <https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0>

* <https://zh.wikipedia.org/wiki/%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%96%B9%E6%B3%95>

* <https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE>

* <https://zh.wikipedia.org/wiki/%E5%90%89%E5%B8%83%E6%96%AF%E9%87%87%E6%A0%B7>

* <https://zh.wikipedia.org/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B>

* <https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95>

* <https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95>

* <https://zh.wikipedia.org/wiki/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95>

* <https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91>
